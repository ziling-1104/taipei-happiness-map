# services/opendata.py
# -*- coding: utf-8 -*-
import json
import pandas as pd
import os
import requests
import io # å¼•å…¥ io æ¨¡çµ„
import numpy as np # å¼•å…¥ numpy æ¨¡çµ„

# è‡ºåŒ—å¸‚ç«‹ç¾è¡“é¤¨çš„å›ºå®šç¶“ç·¯åº¦
TAIPEI_FINE_ARTS_MUSEUM_LAT = 25.0747
TAIPEI_FINE_ARTS_MUSEUM_LON = 121.5209

# OpenData API é€£çµ
OPENDATA_APIS = {
    "art_events": "https://data.taipei/api/frontstage/tpeod/dataset/resource.download?rid=1700a7e6-3d27-47f9-89d9-1811c9f7489c", # æ›´æ”¹å› CSV é€£çµ
    "noise": "https://data.taipei/api/v1/dataset/ac5e1557-5590-4bec-8709-e5f0f8d4bd1e?scope=resourceAquire",
    "sports": "https://data.taipei/api/v1/dataset/112521a2-7ee3-4c15-8495-9ddb3278ce75?scope=resourceAquire",
    "air": "https://data.taipei/api/v1/dataset/2382aab0-6814-46bd-99e5-56a65eecace5?scope=resourceAquire",
    "parks": "https://parks.gov.taipei/parks/api/", # æ–°å¢å…¬åœ’ API
    "youbike": "https://tcgbusfs.blob.core.windows.net/dotapp/youbike/v2/youbike_immediate.json", # æ–°å¢ YouBike API
}

def fetch_data_from_url(url, category, lat_col=None, lon_col=None, value_col=None, name_col=None, default_value=1.0):
    print(f"ğŸ“¡ æ­£åœ¨å¾ {url} ç²å– {category} è³‡æ–™...")
    try:
        response = requests.get(url, timeout=10, verify=False)
        response.raise_for_status() # æª¢æŸ¥ HTTP è«‹æ±‚æ˜¯å¦æˆåŠŸ
        
        # æ ¹æ“šä¸åŒçš„ API çµæ§‹èª¿æ•´è³‡æ–™è§£ææ–¹å¼
        if category == "parks":
            data = response.json() # å…¬åœ’ API çš„é ‚å±¤å°±æ˜¯é™£åˆ—
        elif category == "youbike": # YouBike API çš„é ‚å±¤ä¹Ÿæ˜¯é™£åˆ—
            data = response.json()
        else:
            data = response.json()["result"]["results"]
        
        df = pd.DataFrame(data)

        if df.empty:
            print(f"[WARN] {category} è³‡æ–™ç‚ºç©ºã€‚")
            return pd.DataFrame()

        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        df["category"] = category
        df["name"] = df[name_col] if name_col else "æœªå‘½ååœ°é»"
        df["lat"] = pd.to_numeric(df[lat_col], errors='coerce') if lat_col else None
        df["lon"] = pd.to_numeric(df[lon_col], errors='coerce') if lon_col else None
        df["value"] = pd.to_numeric(df[value_col], errors='coerce') if value_col else default_value

        # è™•ç†ç¼ºå¤±çš„ç¶“ç·¯åº¦
        df.dropna(subset=["lat", "lon"], inplace=True)

        print(f"[OK] {category} è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå…± {len(df)} ç­†ã€‚")
        return df[["name", "category", "lat", "lon", "value"]]
    except requests.exceptions.RequestException as e:
        print(f"[ERR] ç„¡æ³•å¾ {url} ç²å– {category} è³‡æ–™ï¼š{e}")
        return pd.DataFrame()
    except KeyError as e:
        print(f"[ERR] {category} è³‡æ–™ JSON çµæ§‹éŒ¯èª¤ï¼š{e}")
        return pd.DataFrame()
    except Exception as e:
        print(f"[ERR] è™•ç† {category} è³‡æ–™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
        return pd.DataFrame()

def fetch_art_events():
    url = OPENDATA_APIS["art_events"]
    print(f"ğŸ“¡ æ­£åœ¨å¾ CSV é€£çµ {url} ç²å– art_events è³‡æ–™...")
    try:
        response = requests.get(url, timeout=10, verify=False)
        response.raise_for_status()
        # è®€å– CSV å…§å®¹
        csv_content = io.StringIO(response.text)
        df = pd.read_csv(csv_content)

        if df.empty:
            print(f"[WARN] art_events è³‡æ–™ç‚ºç©ºã€‚")
            return pd.DataFrame()

        df["category"] = "art_events"
        df["name"] = df["title"]
        
        # åœ¨ç¾è¡“é¤¨ç¶“ç·¯åº¦åŸºç¤ä¸Šå¢åŠ éš¨æ©Ÿåç§»
        random_offset_lat = (np.random.rand(len(df)) - 0.5) * 0.01  # -0.005 åˆ° +0.005 ä¹‹é–“
        random_offset_lon = (np.random.rand(len(df)) - 0.5) * 0.01  # -0.005 åˆ° +0.005 ä¹‹é–“

        df["lat"] = TAIPEI_FINE_ARTS_MUSEUM_LAT + random_offset_lat
        df["lon"] = TAIPEI_FINE_ARTS_MUSEUM_LON + random_offset_lon
        df["value"] = 1.0 # æ¯å€‹å±•è¦½éƒ½ç®—ä¸€å€‹é»

        df.dropna(subset=["lat", "lon"], inplace=True)

        print(f"[OK] art_events è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå…± {len(df)} ç­†ã€‚")
        return df[["name", "category", "lat", "lon", "value"]]
    except requests.exceptions.RequestException as e:
        print(f"[ERR] ç„¡æ³•å¾ CSV é€£çµ {url} ç²å– art_events è³‡æ–™ï¼š{e}")
        return pd.DataFrame()
    except Exception as e:
        print(f"[ERR] è™•ç† art_events CSV è³‡æ–™æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
        return pd.DataFrame()

def fetch_noise_monitoring():
    df = fetch_data_from_url(
        OPENDATA_APIS["noise"],
        "noise",
        name_col="æ¸¬é»åç¨±",
        lat_col="ç·¯åº¦",
        lon_col="ç¶“åº¦",
        value_col=None, # å™ªéŸ³ç›£æ¸¬é»æ²’æœ‰ç›´æ¥çš„å™ªéŸ³æ•¸å€¼ï¼Œæš«æ™‚çµ¦é è¨­å€¼
        default_value=50.0 # å‡è¨­ä¸€å€‹ä¸­ç­‰å™ªéŸ³å€¼
    )
    # å™ªéŸ³æ•¸å€¼æ‡‰è©²æ˜¯è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥é€™è£¡çš„ value éœ€è¦åœ¨ happiness.py ä¸­åå‘è™•ç†
    return df

def fetch_sports_facilities():
    return fetch_data_from_url(
        OPENDATA_APIS["sports"],
        "sports",
        name_col="å» å•†åç¨±_å¸‚æ‹›",
        lat_col="ç·¯åº¦",
        lon_col="ç¶“åº¦",
        value_col=None,
        default_value=1.0 # æ¯å€‹å ´é¤¨éƒ½ç®—ä¸€å€‹é»
    )

def fetch_air_quality():
    return fetch_data_from_url(
        OPENDATA_APIS["air"],
        "air",
        name_col="name", # æ›´æ­£ç‚º "name"
        lat_col="lat",
        lon_col="lon",
        value_col="value", # æ›´æ­£ç‚º "value"
        default_value=20.0
    )

def load_local_parks():
    # å¾ OpenData API ç²å–å…¬åœ’è³‡æ–™
    return fetch_data_from_url(
        OPENDATA_APIS["parks"],
        "parks",
        name_col="pm_name",
        lat_col="pm_Latitude",
        lon_col="pm_Longitude",
        value_col=None, # å…¬åœ’æ²’æœ‰ç›´æ¥çš„æ•¸å€¼ï¼Œçµ¦é è¨­å€¼
        default_value=1.0
    )

def fetch_youbike_stations():
    # å¾ OpenData API ç²å– YouBike ç«™é»è³‡æ–™
    return fetch_data_from_url(
        OPENDATA_APIS["youbike"],
        "youbike",
        name_col="sna", # ç«™é»åç¨±
        lat_col="latitude", # ç·¯åº¦
        lon_col="longitude", # ç¶“åº¦
        value_col="available_rent_bikes", # å¯ç§Ÿå€Ÿè»Šè¼›æ•¸ä½œç‚ºæ•¸å€¼
        default_value=0 # é è¨­ç‚º 0
    )

def load_all_opendata_spots():
    cache_file = os.path.join(os.path.dirname(__file__), "..", "cache", "spots_cache.json")
    
    # å˜—è©¦å¾å¿«å–è¼‰å…¥
    if os.path.exists(cache_file):
        try:
            print(f"ğŸ’¾ æ­£åœ¨å¾å¿«å–æª”æ¡ˆ {cache_file} è¼‰å…¥è³‡æ–™...")
            master_df = pd.read_json(cache_file)
            print(f"âœ… å¾å¿«å–è¼‰å…¥å®Œæˆï¼Œå…± {len(master_df)} ç­†è³‡æ–™ã€‚")
            return master_df
        except Exception as e:
            print(f"[ERR] ç„¡æ³•å¾å¿«å–è¼‰å…¥è³‡æ–™ï¼š{e}ï¼Œå°‡å˜—è©¦é‡æ–°ç²å– OpenDataã€‚")

    dfs = []
    dfs.append(fetch_art_events())
    dfs.append(fetch_noise_monitoring())
    dfs.append(fetch_sports_facilities())
    dfs.append(fetch_air_quality())
    dfs.append(load_local_parks()) # è¼‰å…¥æœ¬åœ°å…¬åœ’è³‡æ–™
    dfs.append(fetch_youbike_stations()) # è¼‰å…¥ YouBike ç«™é»è³‡æ–™

    # éæ¿¾æ‰ç©ºçš„ DataFrame
    dfs = [df for df in dfs if not df.empty]

    if not dfs:
        print("[ERR] æ²’æœ‰ä»»ä½• OpenData è³‡æ–™æˆåŠŸè¼‰å…¥ï¼")
        return pd.DataFrame()

    master = pd.concat(dfs, ignore_index=True)
    print(f"âœ… OpenData è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå…± {len(master)} ç­†ã€‚")

    # å°‡è³‡æ–™å­˜å…¥å¿«å–
    try:
        master.to_json(cache_file, orient="records", force_ascii=False, indent=2)
        print(f"ğŸ’¾ è³‡æ–™å·²æˆåŠŸå­˜å…¥å¿«å–æª”æ¡ˆ {cache_file}ã€‚")
    except Exception as e:
        print(f"[ERR] ç„¡æ³•å°‡è³‡æ–™å­˜å…¥å¿«å–ï¼š{e}")

    return master
